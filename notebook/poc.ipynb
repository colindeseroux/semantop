{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "541eb93d",
   "metadata": {},
   "source": [
    "# Semantop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568d0c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2025 Colin de Seroux alias Phenix333 (https://colindeseroux.fr)\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e718ee",
   "metadata": {},
   "source": [
    "## <span style=\"color:#10c0ff\">Dependencies installation</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a723c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ca79af",
   "metadata": {},
   "source": [
    "## <span style=\"color:#10c0ff\">Dependencies importation</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14762e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from huggingface_hub import hf_hub_download\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import os\n",
    "from os import path as osp\n",
    "import random\n",
    "import requests\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e1bc08",
   "metadata": {},
   "source": [
    "## <span style=\"color:#10c0ff\">Environment</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812f28cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MODEL = \"frWac_no_postag_no_phrase_700_skip_cut50\"\n",
    "DICO_DELA = \"http://infolingu.univ-mlv.fr/DonneesLinguistiques/Dictionnaires/dela-fr-public.zip?B1=T%E9l%E9charger\"\n",
    "DICO_HBENBEL = \"https://raw.githubusercontent.com/hbenbel/French-Dictionary/refs/heads/master/dictionary\"\n",
    "HUGGINGFACE = \"colindeseroux/semantop\"\n",
    "DICO_EXIST = osp.exists(f\"../models/dico.dic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211ee89d",
   "metadata": {},
   "source": [
    "## <span style=\"color:#10c0ff\">Download models</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d3196e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"../models\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773bae83",
   "metadata": {},
   "source": [
    "### <span style=\"color:#10ff41\">Download embedding model</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1293efa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if osp.exists(f\"../models/{MODEL}.bin\"):\n",
    "    print(f\"File ../models/{MODEL}.bin already exists.\")\n",
    "else:\n",
    "    with open(f\"../models/{MODEL}.bin\", \"wb\") as f:\n",
    "        f.write(requests.get(f\"https://embeddings.net/embeddings/{MODEL}.bin\").content)\n",
    "    \n",
    "    print(f\"File ../models/{MODEL} downloaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32899713",
   "metadata": {},
   "source": [
    "### <span style=\"color:#10ff41\">Download correct word files</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a54e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not DICO_EXIST:\n",
    "    with open(\"../models/dico.zip\", \"wb\") as f:\n",
    "        f.write(requests.get(DICO_DELA).content)\n",
    "\n",
    "    with zipfile.ZipFile(\"../models/dico.zip\", \"r\") as zip_ref:\n",
    "        with zip_ref.open(\"dela-fr-public.dic\") as source, open(\"../models/dela-dico.dic\", \"wb\") as target:\n",
    "            target.write(source.read())\n",
    "    \n",
    "    print(f\"File ../models/dela-dico.dic downloaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8360b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"adj\", \"adv\", \"noun\", \"verb\"]\n",
    "\n",
    "if not DICO_EXIST:\n",
    "    for f in files:\n",
    "        response = requests.get(f\"{DICO_HBENBEL}/{f}.csv\")\n",
    "        \n",
    "        with open(f\"../models/{f}.csv\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410dec5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not DICO_EXIST and not osp.exists(f\"../models/custom.dic\"):\n",
    "    try:\n",
    "        hf_hub_download(\n",
    "            repo_id=HUGGINGFACE,\n",
    "            filename=\"custom.dic\",\n",
    "            local_dir=\"../models\",\n",
    "            local_dir_use_symlinks=False\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading custom.dic: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274b639e",
   "metadata": {},
   "source": [
    "## <span style=\"color:#10c0ff\">Preprocessing the dico</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fca5bfa",
   "metadata": {},
   "source": [
    "### <span style=\"color:#10ff41\">Load correct_words if `dico.dic` exist</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257db7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_words = []\n",
    "\n",
    "if DICO_EXIST:\n",
    "    print(f\"File ../models/dico.dic already exists.\")\n",
    "    \n",
    "    with open(\"../models/dico.dic\", \"r\", encoding=\"utf-8\") as f:\n",
    "        correct_words = [word.replace(\"\\n\", \"\") for word in f]\n",
    "    \n",
    "    print(f\"Loaded {len(correct_words)} words from dico.dic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526ad708",
   "metadata": {},
   "source": [
    "### <span style=\"color:#10ff41\">Preprocessing `dela-dico.dic` to keep only the base of words</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9f1d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not DICO_EXIST:\n",
    "    nouns = []\n",
    "    verbs = []\n",
    "    adjectives = []\n",
    "\n",
    "    with open(\"../models/dela-dico.dic\", \"r\", encoding=\"utf-16\") as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                # Strip whitespace and split on comma\n",
    "                line = line.strip()\n",
    "                line.replace(\"\\\\-\", \"-\")\n",
    "                \n",
    "                # Only singular words or base forms\n",
    "                if \":ms\" in line or \":fs\" in line or line.endswith(\":W\"):\n",
    "                    # Extract word and its classification\n",
    "                    if \",.N\" in line and \"NPropre\" not in line:\n",
    "                        word = line.split(\",\")[0]\n",
    "                        nouns.append(word)\n",
    "                    elif \",.V\" in line:\n",
    "                        word = line.split(\",\")[0]\n",
    "                        verbs.append(word)\n",
    "                    elif \",.A\" in line:\n",
    "                        word = line.split(\",\")[0]\n",
    "                        adjectives.append(word)\n",
    "            except Exception as e:\n",
    "                continue\n",
    "\n",
    "    correct_words = nouns + verbs + adjectives\n",
    "\n",
    "    print(f\"Found {len(adjectives)} adjectives, {len(nouns)} nouns and {len(verbs)} verbs \")\n",
    "    print(f\"Total correct words in dico.dic: {len(correct_words)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda364f3",
   "metadata": {},
   "source": [
    "### <span style=\"color:#10ff41\">Preprocessing `adj.csv`, `adv.csv`, `noun.csv` and `verb.csv` to keep only the base of words</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802bded5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not DICO_EXIST:\n",
    "    words = {\n",
    "        \"adj\": 0,\n",
    "        \"adv\": 0,\n",
    "        \"noun\": 0,\n",
    "        \"verb\": 0\n",
    "    }\n",
    "    \n",
    "    for f_n in files:\n",
    "        with open(f\"../models/{f_n}.csv\", \"r\", encoding=\"utf-8\") as f:\n",
    "            lines = f.readlines()\n",
    "            \n",
    "            matching_lines = []\n",
    "            \n",
    "            for line in lines:\n",
    "                line = line.strip()\n",
    "                \n",
    "                if f_n == \"verb\":\n",
    "                    if line.endswith(\",['infinitive']\"):\n",
    "                        matching_lines.append(line.replace(\",['infinitive']\", \"\"))\n",
    "                else:\n",
    "                    if line.endswith(\",\"):\n",
    "                        matching_lines.append(line.replace(\",\", \"\"))\n",
    "            \n",
    "            words[f_n] = len(matching_lines)\n",
    "            \n",
    "            correct_words.extend(matching_lines)\n",
    "    \n",
    "    print(f\"Found {words['adj']} adjectives, {words['adv']} adverbs, {words['noun']} nouns and {words['verb']} verbs\")\n",
    "    print(f\"Total correct words in adj.csv + adv.csv + noun.csv + verb.csv: {words['adj'] + words['adv'] + words['noun'] + words['verb']}\")            \n",
    "    print(f\"Total correct words in dico.dic: {len(correct_words)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfa9b7f",
   "metadata": {},
   "source": [
    "### <span style=\"color:#10ff41\">Add custom words</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d89c543",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not DICO_EXIST:\n",
    "    with open(f\"../models/custom.dic\", \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "        correct_words.extend([word.replace(\"\\n\", \"\") for word in lines])\n",
    "    \n",
    "    print(f\"Total correct words in dico.dic: {len(correct_words)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078b9573",
   "metadata": {},
   "source": [
    "### <span style=\"color:#10ff41\">Delete short words (not useful in me yousecase)</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3959ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not DICO_EXIST:\n",
    "    correct_words = [word for word in correct_words if len(word) >= 3]\n",
    "    # Remove duplicates from the correct_words list to ensure uniqueness\n",
    "    correct_words = list(set(correct_words))\n",
    "    print(f\"Total correct words in dico.dic: {len(correct_words)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fdad56",
   "metadata": {},
   "source": [
    "## <span style=\"color:#10c0ff\">Create the custom model</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d810d6d",
   "metadata": {},
   "source": [
    "### <span style=\"color:#10ff41\">Load the model</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da30cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyedVectors.load_word2vec_format(f\"../models/{MODEL}.bin\", binary=True, unicode_errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec19690",
   "metadata": {},
   "source": [
    "### <span style=\"color:#10ff41\">Download / load french stopwords from nltk</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d188dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not DICO_EXIST:\n",
    "    nltk.download(\"stopwords\")\n",
    "    french_stopwords = set(stopwords.words(\"french\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9582b7",
   "metadata": {},
   "source": [
    "### <span style=\"color:#10ff41\">Delete stopwords</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15cb392",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not DICO_EXIST:\n",
    "    filtered_keys_without_stopwords = [word for word in model.index_to_key if word not in french_stopwords]\n",
    "    filtered_keys_without_stopwords.append(\"été\")\n",
    "    print(f\"Filtered keys without stopwords: {len(filtered_keys_without_stopwords)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2cce19",
   "metadata": {},
   "source": [
    "### <span style=\"color:#10ff41\">Keep only correct words if they exist in the model</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0111ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not DICO_EXIST:\n",
    "    correct_filtered_keys = [word for word in filtered_keys_without_stopwords if word in correct_words]\n",
    "    print(f\"Correct filtered keys: {len(correct_filtered_keys)}\")\n",
    "    \n",
    "    correct_words = correct_filtered_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab0f4b3",
   "metadata": {},
   "source": [
    "Just in case you re-launch the creation of a new model without paying attention.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c64dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not DICO_EXIST:\n",
    "    with open(\"../models/dico.dic\", \"w\", encoding=\"utf-8\") as f:      \n",
    "        for word in correct_filtered_keys:\n",
    "            f.write(word + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d65fee",
   "metadata": {},
   "source": [
    "### <span style=\"color:#10ff41\">Save the model</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0516e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not osp.exists(f\"../models/{MODEL}_custom.bin\"):\n",
    "    custom_model = KeyedVectors(vector_size=model.vector_size)\n",
    "    custom_model.add_vectors(correct_words, [model[word] for word in correct_words])\n",
    "    custom_model.save_word2vec_format(f\"../models/{MODEL}_custom.bin\", binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d96b0db",
   "metadata": {},
   "source": [
    "## <span style=\"color:#10c0ff\">Test the custom model</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8300e5",
   "metadata": {},
   "source": [
    "You can download directely the custom model on [HuggingFace](https://huggingface.co/datasets/colindeseroux/semantop).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3e168b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not osp.exists(f\"../models/{MODEL}_custom.bin\"):\n",
    "    try:\n",
    "        hf_hub_download(\n",
    "            repo_id=HUGGINGFACE,\n",
    "            filename=f\"{MODEL}_custom.bin\",\n",
    "            local_dir=\"../models\",\n",
    "            local_dir_use_symlinks=False\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading {MODEL}_custom.bin: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81da3560",
   "metadata": {},
   "source": [
    "### <span style=\"color:#10ff41\">Load the model</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe1ac43",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model = KeyedVectors.load_word2vec_format(f\"../models/{MODEL}_custom.bin\", binary=True, unicode_errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743c676e",
   "metadata": {},
   "source": [
    "### <span style=\"color:#10ff41\">Get random word</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba48184",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_word = random.choice(list(custom_model.index_to_key))\n",
    "print(f\"Random word from the model: {random_word}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fc4dc9",
   "metadata": {},
   "source": [
    "### <span style=\"color:#10ff41\">Get similar words</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73b588b",
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_words = custom_model.similar_by_word(random_word, topn=10)\n",
    "\n",
    "print(\"Most similar words:\")\n",
    "\n",
    "for word, similarity in similar_words:\n",
    "    print(f\"{word}: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a2fe3b",
   "metadata": {},
   "source": [
    "### <span style=\"color:#10ff41\">Test word</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c370b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = custom_model.similarity(random_word, \"chat\")\n",
    "print(f\"Similarity between '{random_word}' and 'chat': {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ce2ee9",
   "metadata": {},
   "source": [
    "### <span style=\"color:#10ff41\">Bot</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbeefbc",
   "metadata": {},
   "source": [
    "Test the model with assert in reverse.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f202e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"cbow\" in MODEL:\n",
    "    TARGETS = {\n",
    "        \"chat\": -0.0195,\n",
    "        \"minou\": 0.0167\n",
    "    }\n",
    "else:\n",
    "    TARGETS = {\n",
    "        \"chat\": 0.0374,\n",
    "        \"minou\": 0.0350\n",
    "    }\n",
    "\n",
    "\n",
    "def distance_scores(word: str, vectors: list, targets: list, model: KeyedVectors) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the cumulative squared error between the similarity of a word and target values.\n",
    "    \n",
    "    :param word: The word to evaluate.\n",
    "    :type word: str\n",
    "    :param vectors: List of reference words to compare against.\n",
    "    :type vectors: list\n",
    "    :param targets: List of target similarity values corresponding to the reference words.\n",
    "    :type targets: list\n",
    "    :param model: The word embedding model.\n",
    "    :type model: KeyedVectors\n",
    "    \n",
    "    :return: Cumulative squared error.\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "    \n",
    "    if word not in model:\n",
    "        return float(\"inf\")\n",
    "    \n",
    "    score = 0.0\n",
    "    \n",
    "    for word_ref, target in zip(vectors, targets):\n",
    "        sim = model.similarity(word, word_ref)\n",
    "        score += (sim - target) ** 2\n",
    "        \n",
    "    return score\n",
    "\n",
    "ref_words = list(TARGETS.keys())\n",
    "target_values = list(TARGETS.values())\n",
    "\n",
    "scores = []\n",
    "\n",
    "for word in custom_model.index_to_key:\n",
    "    if word in ref_words:\n",
    "        continue\n",
    "\n",
    "    dist = distance_scores(word, ref_words, target_values, custom_model)\n",
    "    scores.append((word, dist))\n",
    "\n",
    "scores = sorted(scores, key=lambda x: x[1])\n",
    "\n",
    "assert scores[0][0] == \"colin\" # If not True, the model is not working as expected\n",
    "\n",
    "print(\"Words closest to the combination :\")\n",
    "\n",
    "for word, error in scores[:10]:\n",
    "    print(f\"{word} (cumulative squared error: {error:.4f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semantop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
