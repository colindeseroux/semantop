{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "541eb93d",
   "metadata": {},
   "source": [
    "# Semantop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568d0c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2025 Colin de Seroux alias Phenix333 (https://colindeseroux.fr)\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e718ee",
   "metadata": {},
   "source": [
    "## <span style=\"color:#10c0ff\">Dependencies installation</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a723c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ca79af",
   "metadata": {},
   "source": [
    "## <span style=\"color:#10c0ff\">Dependencies importation</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14762e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import os\n",
    "from os import path as osp\n",
    "import random\n",
    "import requests\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e1bc08",
   "metadata": {},
   "source": [
    "## <span style=\"color:#10c0ff\">Environment</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812f28cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"frWac_no_postag_phrase_500_cbow_cut10\"\n",
    "DICO_DELA = \"http://infolingu.univ-mlv.fr/DonneesLinguistiques/Dictionnaires/dela-fr-public.zip?B1=T%E9l%E9charger\"\n",
    "DICO_HBENBEL = \"https://raw.githubusercontent.com/hbenbel/French-Dictionary/refs/heads/master/dictionary\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211ee89d",
   "metadata": {},
   "source": [
    "## <span style=\"color:#10c0ff\">Download models</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d3196e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"../models\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773bae83",
   "metadata": {},
   "source": [
    "### <span style=\"color:#10ff41\">Download embedding model</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1293efa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if osp.exists(f\"../models/{MODEL}.bin\"):\n",
    "    print(f\"File ../models/{MODEL}.bin already exists.\")\n",
    "else:\n",
    "    with open(f\"../models/{MODEL}.bin\", \"wb\") as f:\n",
    "        f.write(requests.get(f\"https://embeddings.net/embeddings/{MODEL}.bin\").content)\n",
    "    \n",
    "    print(f\"File ../models/{MODEL} downloaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32899713",
   "metadata": {},
   "source": [
    "### <span style=\"color:#10ff41\">Download correct word files</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a54e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "if osp.exists(f\"../models/dico.dic\"):\n",
    "    print(f\"File ../models/dico.dic already exists.\")\n",
    "else:\n",
    "    with open(\"../models/dico.zip\", \"wb\") as f:\n",
    "        f.write(requests.get(DICO_DELA).content)\n",
    "\n",
    "    with zipfile.ZipFile(\"../models/dico.zip\", \"r\") as zip_ref:\n",
    "        with zip_ref.open(\"dela-fr-public.dic\") as source, open(\"../models/dico.dic\", \"wb\") as target:\n",
    "            target.write(source.read())\n",
    "    \n",
    "    print(f\"File ../models/dico.dic downloaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8360b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"adj\", \"adv\", \"noun\", \"verb\"]\n",
    "\n",
    "if osp.exists(f\"../models/dico.csv\"):\n",
    "    print(f\"File ../models/dico.csv already exists.\")\n",
    "else:\n",
    "    for f in files:\n",
    "        response = requests.get(f\"{DICO_HBENBEL}/{f}.csv\")\n",
    "        \n",
    "        with open(f\"../models/{f}.csv\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274b639e",
   "metadata": {},
   "source": [
    "## <span style=\"color:#10c0ff\">Preprocessing the dico</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fca5bfa",
   "metadata": {},
   "source": [
    "### <span style=\"color:#10ff41\">Load correct_words if `dico.csv` exist</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257db7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_words = []\n",
    "\n",
    "if osp.exists(f\"../models/dico.csv\"):\n",
    "    print(f\"File ../models/dico.csv already exists.\")\n",
    "    \n",
    "    with open(\"../models/dico.csv\", \"r\", encoding=\"utf-8\") as f:\n",
    "        correct_words = [word for word in f]\n",
    "    \n",
    "    print(f\"Loaded {len(correct_words)} words from dico.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526ad708",
   "metadata": {},
   "source": [
    "### <span style=\"color:#10ff41\">Preprocessing `dico.dic` to keep only the base of words</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9f1d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not osp.exists(f\"../models/dico.csv\"):\n",
    "    nouns = []\n",
    "    verbs = []\n",
    "    adjectives = []\n",
    "\n",
    "    with open(\"../models/dico.dic\", \"r\", encoding=\"utf-16\") as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                # Strip whitespace and split on comma\n",
    "                line = line.strip()\n",
    "                \n",
    "                # Extract word and its classification\n",
    "                if \",.N\" in line and \"NPropre\" not in line:\n",
    "                    word = line.split(',')[0]\n",
    "                    nouns.append(word)\n",
    "                elif \",.V\" in line:\n",
    "                    word = line.split(',')[0]\n",
    "                    verbs.append(word)\n",
    "                elif \",.A\" in line:\n",
    "                    word = line.split(',')[0]\n",
    "                    adjectives.append(word)\n",
    "            except Exception as e:\n",
    "                continue\n",
    "\n",
    "    correct_words = nouns + verbs + adjectives\n",
    "\n",
    "    print(f\"Found {len(adjectives)} adjectives, {len(nouns)} nouns and {len(verbs)} verbs \")\n",
    "    print(f\"Total correct words in dico.dic: {len(correct_words)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cbd056",
   "metadata": {},
   "source": [
    "Found 35650 adjectives, 128600 nouns and 12109 verbs  \n",
    "Total correct words in dico.dic: 176359\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda364f3",
   "metadata": {},
   "source": [
    "### <span style=\"color:#10ff41\">Preprocessing `adj.csv`, `adv.csv`, `noun.csv` and `verb.csv` to keep only the base of words</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802bded5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not osp.exists(f\"../models/dico.csv\"):\n",
    "    words = {\n",
    "        \"adj\": 0,\n",
    "        \"adv\": 0,\n",
    "        \"noun\": 0,\n",
    "        \"verb\": 0\n",
    "    }\n",
    "    \n",
    "    for f_n in files:\n",
    "        with open(f\"../models/{f_n}.csv\", \"r\", encoding=\"utf-8\") as f:\n",
    "            lines = f.readlines()\n",
    "            \n",
    "            matching_lines = []\n",
    "            \n",
    "            for line in lines:\n",
    "                # print(line)\n",
    "                line = line.strip()\n",
    "                \n",
    "                if line.endswith(\",\") or line.endswith(\",['infinitive']\"):\n",
    "                    matching_lines.append(line.replace(\",\", \"\").replace(\"['infinitive']\", \"\"))\n",
    "            \n",
    "            words[f_n] = len(matching_lines)\n",
    "            \n",
    "            correct_words.extend(matching_lines)\n",
    "    \n",
    "    print(f\"Found {words['adj']} adjectives, {words['adv']} adverbs, {words['noun']} nouns and {words['verb']} verbs\")\n",
    "    print(f\"Total correct words in adj.csv + adv.csv + noun.csv + verb.csv: {words['adj'] + words['adv'] + words['noun'] + words['verb']}\")\n",
    "    \n",
    "    # Remove duplicates from the correct_words list to ensure uniqueness\n",
    "    correct_words = list(set(correct_words))\n",
    "            \n",
    "    print(f\"Found {len(correct_words)} correct words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99c373b",
   "metadata": {},
   "source": [
    "Found 16338 adjectives, 4229 adverbs, 43102 nouns and 14095 verbs  \n",
    "Total correct words in adj.csv + adv.csv + noun.csv + verb.csv: 77764  \n",
    "Found 191233 correct words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f233cf",
   "metadata": {},
   "source": [
    "### <span style=\"color:#10ff41\">Save correct_words in `dico.csv` if `dico.csv` do not exist</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f66bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not osp.exists(f\"../models/dico.csv\"):\n",
    "    with open(\"../models/dico.csv\", \"w\", encoding=\"utf-8\") as f:      \n",
    "        for word in correct_words:\n",
    "            f.write(word + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fdad56",
   "metadata": {},
   "source": [
    "## <span style=\"color:#10c0ff\">Create the custom model</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d810d6d",
   "metadata": {},
   "source": [
    "### <span style=\"color:#10ff41\">Load the model</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da30cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyedVectors.load_word2vec_format(f\"../models/{MODEL}.bin\", binary=True, unicode_errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec19690",
   "metadata": {},
   "source": [
    "### <span style=\"color:#10ff41\">Download / load french stopwords from nltk</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d188dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "french_stopwords = set(stopwords.words(\"french\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9582b7",
   "metadata": {},
   "source": [
    "### <span style=\"color:#10ff41\">Delete stopwords</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15cb392",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_keys_without_stopwords = [word for word in model.index_to_key if word not in french_stopwords]\n",
    "print(f\"Filtered keys without stopwords: {len(filtered_keys_without_stopwords)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa90685e",
   "metadata": {},
   "source": [
    "Filtered keys without stopwords: 1081851\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2cce19",
   "metadata": {},
   "source": [
    "### <span style=\"color:#10ff41\">Keep only correct words if they exist in the model</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0111ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_filtered_keys = [word for word in correct_words if word in filtered_keys_without_stopwords]\n",
    "print(f\"Correct filtered keys: {len(correct_filtered_keys)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a50db83",
   "metadata": {},
   "source": [
    "Correct filtered keys: 61775\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab0f4b3",
   "metadata": {},
   "source": [
    "Just in case you re-launch the creation of a new model without paying attention.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c64dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not osp.exists(f\"../models/correct_filtered_keys.csv\"):\n",
    "    with open(\"../models/correct_filtered_keys.csv\", \"w\", encoding=\"utf-8\") as f:      \n",
    "        for word in correct_filtered_keys:\n",
    "            f.write(word + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d65fee",
   "metadata": {},
   "source": [
    "### <span style=\"color:#10ff41\">Save the model</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0516e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model = KeyedVectors(vector_size=model.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a5da24",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model.add_vectors(correct_filtered_keys, [model[word] for word in correct_filtered_keys])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420b7146",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model.save_word2vec_format(f\"../models/{MODEL}_custom.bin\", binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d96b0db",
   "metadata": {},
   "source": [
    "## <span style=\"color:#10c0ff\">Test the custom model</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8300e5",
   "metadata": {},
   "source": [
    "You can download directely the custom model on [HuggingFace](https://huggingface.co/datasets/colindeseroux/semantop).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81da3560",
   "metadata": {},
   "source": [
    "### <span style=\"color:#10ff41\">Load the model</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe1ac43",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model = KeyedVectors.load_word2vec_format(f\"../models/{MODEL}_custom.bin\", binary=True, unicode_errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743c676e",
   "metadata": {},
   "source": [
    "### <span style=\"color:#10ff41\">Get random word</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba48184",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_word = random.choice(list(custom_model.index_to_key))\n",
    "print(f\"Random word from the model: {random_word}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fc4dc9",
   "metadata": {},
   "source": [
    "### <span style=\"color:#10ff41\">Get similar words</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73b588b",
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_words = custom_model.similar_by_word(random_word, topn=10)\n",
    "\n",
    "print(\"Most similar words:\")\n",
    "\n",
    "for word, similarity in similar_words:\n",
    "    print(f\"{word}: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a2fe3b",
   "metadata": {},
   "source": [
    "### <span style=\"color:#10ff41\">Test word</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c370b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = custom_model.similarity(random_word, \"chat\")\n",
    "print(f\"Similarity between '{random_word}' and 'chat': {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ce2ee9",
   "metadata": {},
   "source": [
    "### <span style=\"color:#10ff41\">Bot</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbeefbc",
   "metadata": {},
   "source": [
    "Test the model with assert in reverse.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f202e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGETS = {\n",
    "    \"chat\": -0.0195,\n",
    "    \"minou\": 0.0167\n",
    "}\n",
    "\n",
    "\n",
    "def distance_scores(word: str, vectors: list, targets: list, model: KeyedVectors) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the cumulative squared error between the similarity of a word and target values.\n",
    "    \n",
    "    :param word: The word to evaluate.\n",
    "    :type word: str\n",
    "    :param vectors: List of reference words to compare against.\n",
    "    :type vectors: list\n",
    "    :param targets: List of target similarity values corresponding to the reference words.\n",
    "    :type targets: list\n",
    "    :param model: The word embedding model.\n",
    "    :type model: KeyedVectors\n",
    "    \n",
    "    :return: Cumulative squared error.\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "    \n",
    "    if word not in model:\n",
    "        return float(\"inf\")\n",
    "    \n",
    "    score = 0.0\n",
    "    \n",
    "    for word_ref, target in zip(vectors, targets):\n",
    "        sim = model.similarity(word, word_ref)\n",
    "        score += (sim - target) ** 2\n",
    "        \n",
    "    return score\n",
    "\n",
    "ref_words = list(TARGETS.keys())\n",
    "target_values = list(TARGETS.values())\n",
    "\n",
    "scores = []\n",
    "\n",
    "for word in custom_model.index_to_key:\n",
    "    if word in ref_words:\n",
    "        continue\n",
    "\n",
    "    dist = distance_scores(word, ref_words, target_values, custom_model)\n",
    "    scores.append((word, dist))\n",
    "\n",
    "scores = sorted(scores, key=lambda x: x[1])\n",
    "\n",
    "assert scores[0][0] == \"colin\" # If not True, the model is not working as expected\n",
    "\n",
    "print(\"Words closest to the combination :\")\n",
    "\n",
    "for word, error in scores[:10]:\n",
    "    print(f\"{word} (cumulative squared error: {error:.4f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semantop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
